{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added required libraries\n",
      "Declared various required path locations\n",
      "Got JVM flags\n",
      "Found 135 files in data lake store\n",
      "Got file list from Azure data lake storage using JAVA class\n",
      "Finding repeating words in all files\n",
      "Counting repeating words from PDB files\n",
      "\n",
      "Total 45063 repeating words found in PDB files\n",
      "\n",
      "Saving the data for future analysis"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from operator import add\n",
    "from datetime import datetime\n",
    "\n",
    "print('Added required libraries')\n",
    "\n",
    "\n",
    "adlpath_dir = r'adl://merckadl.azuredatalakestore.net/test_file_write/'\n",
    "file_system_base_uri = \"adl://merckadl.azuredatalakestore.net\"\n",
    "adlpath = r'adl://merckadl.azuredatalakestore.net/test_file_write/result.txt'\n",
    "file01 = 'adl://merckadl.azuredatalakestore.net/extracted/pdb1u10.txt'\n",
    "source_folder_localtion = '/extracted/'\n",
    "\n",
    "print('Declared various required path locations')\n",
    "\n",
    "\n",
    "URI           = sc._gateway.jvm.java.net.URI\n",
    "Path          = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "FileSystem    = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "Configuration = sc._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
    "print('Got JVM flags')\n",
    "\n",
    "fs = FileSystem.get(URI(file_system_base_uri), Configuration())\n",
    "status = fs.listStatus(Path(source_folder_localtion))\n",
    "\n",
    "all_files_found = []\n",
    "for fileStatus in status:\n",
    "    all_files_found.append(str(status[0].getPath()))\n",
    "\n",
    "print('Found '+str(len(all_files_found))+' files in data lake store')\n",
    "\n",
    "print('Got file list from Azure data lake storage using JAVA class')\n",
    "#for fileStatus in status:\n",
    "#    print(str(status[0].getPath()))\n",
    "    \n",
    "    \n",
    "print('Finding repeating words in all files')    \n",
    "t1 = datetime.now()\n",
    "lines = spark.read.text(all_files_found).rdd.map(lambda r: r[0])\n",
    "counts = lines.flatMap(lambda x: x.split(' ')) \\\n",
    "                  .map(lambda x: (x, 1)) \\\n",
    "                  .reduceByKey(add)\n",
    "output = counts.collect()\n",
    "t2 = datetime.now()\n",
    "delta = t2 - t1\n",
    "print('Counting repeating words from PDB files')\n",
    "repeated_word_count = 0\n",
    "for (word, count) in output:\n",
    "    if count > 1:\n",
    "        repeated_word_count+=1\n",
    "print('\\nTotal '+str(repeated_word_count)+' repeating words found in PDB files\\n')\n",
    "\n",
    "print('Saving the data for future analysis')\n",
    "counts.saveAsTextFile(adlpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
